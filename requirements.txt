--extra-index-url https://download.pytorch.org/whl/cu124
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

torch==2.4.0+cu124
torchaudio==2.4.0+cu124
torchvision==0.19.0+cu124
fastapi
uvicorn
diffusers
pillow
bitsandbytes
transformers
fastapi[standard]
uuid
huggingface_hub[cli]
uvicorn
sentencepiece
accelerate
optimum
beautifulsoup4
ftfy
llama-cpp-python
